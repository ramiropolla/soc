Index: ffmpeg.c
===================================================================
--- ffmpeg.c	(revision 13595)
+++ ffmpeg.c	(working copy)
@@ -36,6 +36,12 @@
 #include "libavutil/avstring.h"
 #include "libavformat/os_support.h"
 
+#if ENABLE_AVFILTER
+# include "avfilter.h"
+# include "avfiltergraph.h"
+# include "graphparser.h"
+#endif
+
 #ifdef HAVE_SYS_RESOURCE_H
 #include <sys/types.h>
 #include <sys/resource.h>
@@ -136,6 +142,9 @@
 static int loop_input = 0;
 static int loop_output = AVFMT_NOOUTPUTLOOP;
 static int qp_hist = 0;
+#if ENABLE_AVFILTER
+static char *vfilters = NULL;
+#endif
 
 static int intra_only = 0;
 static int audio_sample_rate = 44100;
@@ -274,6 +283,13 @@
                                 is not defined */
     int64_t       pts;       /* current pts */
     int is_start;            /* is 1 at the start and after a discontinuity */
+#if ENABLE_AVFILTER
+    AVFilterContext *out_video_filter;
+    AVFilterContext *input_video_filter;
+    AVFrame *filter_frame;
+    int has_filter_frame;
+    AVFilterPicRef *picref;
+#endif
 } AVInputStream;
 
 typedef struct AVInputFile {
@@ -289,6 +305,266 @@
 static struct termios oldtty;
 #endif
 
+#if ENABLE_AVFILTER
+typedef struct {
+    AVInputStream *ist;
+} FilterInPriv;
+
+static int input_init(AVFilterContext *ctx, const char *args, void *opaque)
+{
+    FilterInPriv *priv = ctx->priv;
+
+    if(!opaque) return -1;
+
+    priv->ist = opaque;
+    priv->ist->filter_frame = avcodec_alloc_frame();
+
+    return 0;
+}
+
+static void input_uninit(AVFilterContext *ctx)
+{
+    FilterInPriv *priv = ctx->priv;
+    av_free(priv->ist->filter_frame);
+}
+
+static int poll_frame(AVFilterLink *link)
+{
+    FilterInPriv *priv = link->src->priv;
+    return !!(priv->ist->has_filter_frame);
+}
+
+static int input_request_frame(AVFilterLink *link)
+{
+    FilterInPriv *priv = link->src->priv;
+    AVFilterPicRef *picref;
+
+    /* This picture will be needed unmodified later for decoding the next
+     * frame */
+    picref = avfilter_get_video_buffer(link, AV_PERM_WRITE | AV_PERM_PRESERVE |
+                                             AV_PERM_REUSE2);
+
+    memcpy(picref->data,     priv->ist->filter_frame->data,
+           sizeof(priv->ist->filter_frame->data));
+
+    memcpy(picref->linesize, priv->ist->filter_frame->linesize,
+           sizeof(priv->ist->filter_frame->linesize));
+
+    picref->pts = priv->ist->pts;
+    picref->pixel_aspect = priv->ist->st->codec->sample_aspect_ratio;
+    avfilter_start_frame(link, avfilter_ref_pic(picref, ~0));
+    avfilter_draw_slice(link, 0, picref->h);
+    avfilter_end_frame(link);
+    avfilter_unref_pic(picref);
+
+    priv->ist->has_filter_frame = 0;
+
+    return 0;
+}
+
+static int input_query_formats(AVFilterContext *ctx)
+{
+    FilterInPriv *priv = ctx->priv;
+    avfilter_set_common_formats(ctx,
+           avfilter_make_format_list(1, priv->ist->st->codec->pix_fmt));
+    return 0;
+}
+
+static int input_config_props(AVFilterLink *link)
+{
+    FilterInPriv *priv  = link->src->priv;
+    AVCodecContext *c = priv->ist->st->codec;
+
+    link->w = c->width;
+    link->h = c->height;
+
+    return 0;
+}
+
+static AVFilter input_filter =
+{
+    .name      = "ffmpeg_input",
+
+    .priv_size = sizeof(FilterInPriv),
+
+    .init      = input_init,
+    .uninit    = input_uninit,
+
+    .query_formats = input_query_formats,
+
+    .inputs    = (AVFilterPad[]) {{ .name = NULL }},
+    .outputs   = (AVFilterPad[]) {{ .name = "default",
+                                    .type = CODEC_TYPE_VIDEO,
+                                    .request_frame = input_request_frame,
+                                    .poll_frame = poll_frame,
+                                    .config_props  = input_config_props, },
+                                  { .name = NULL }},
+};
+
+typedef struct {
+    int pix_fmt;
+} FilterOutPriv;
+
+
+static int output_init(AVFilterContext *ctx, const char *args, void *opaque)
+{
+    FilterOutPriv *priv = ctx->priv;
+
+    if(!opaque) return -1;
+
+    priv->pix_fmt = *((int *)opaque);
+
+    return 0;
+}
+
+static void output_end_frame(AVFilterLink *link)
+{
+}
+
+static int output_query_formats(AVFilterContext *ctx)
+{
+    FilterOutPriv *priv = ctx->priv;
+    avfilter_set_common_formats(ctx,
+           avfilter_make_format_list(1, priv->pix_fmt));
+    return 0;
+}
+
+static int get_filtered_video_pic(AVFilterContext *ctx,
+                                  AVFilterPicRef **picref, AVFrame *pic2,
+                                  uint64_t *pts)
+{
+    AVFilterPicRef *pic;
+
+    if(avfilter_request_frame(ctx->inputs[0]))
+        return -1;
+    if(!(pic = ctx->inputs[0]->cur_pic))
+        return -1;
+    *picref = pic;
+    ctx->inputs[0]->cur_pic = NULL;
+
+    *pts          = pic->pts;
+
+    memcpy(pic2->data,     pic->data,     sizeof(pic->data));
+    memcpy(pic2->linesize, pic->linesize, sizeof(pic->linesize));
+
+    return 1;
+}
+
+static AVFilter output_filter =
+{
+    .name      = "ffmpeg_output",
+
+    .priv_size = sizeof(FilterOutPriv),
+    .init      = output_init,
+
+    .query_formats = output_query_formats,
+
+    .inputs    = (AVFilterPad[]) {{ .name          = "default",
+                                    .type          = CODEC_TYPE_VIDEO,
+                                    .end_frame     = output_end_frame,
+                                    .min_perms     = AV_PERM_READ, },
+                                  { .name = NULL }},
+    .outputs   = (AVFilterPad[]) {{ .name = NULL }},
+};
+
+static int configure_filters(AVInputStream *ist, AVOutputStream *ost)
+{
+    AVFilterContext *curr_filter;
+    /** filter graph containing all filters including input & output */
+    AVFilterGraph *filt_graph_all = av_mallocz(sizeof(AVFilterGraph));
+    AVCodecContext *codec = ost->st->codec;
+    AVCodecContext *icodec = ist->st->codec;
+
+    avfilter_register_all();
+
+    if(!(ist->input_video_filter = avfilter_open(&input_filter, "src")))
+        return -1;
+    if(!(ist->out_video_filter = avfilter_open(&output_filter, "out")))
+        return -1;
+
+    if(avfilter_init_filter(ist->input_video_filter, NULL, ist))
+        return -1;
+    if(avfilter_init_filter(ist->out_video_filter, NULL, &codec->pix_fmt))
+        return -1;
+
+    /* add input and output filters to the overall graph */
+    avfilter_graph_add_filter(filt_graph_all, ist->input_video_filter);
+    avfilter_graph_add_filter(filt_graph_all, ist->out_video_filter);
+
+    curr_filter = ist->input_video_filter;
+
+    if(ost->video_crop) {
+        char crop_args[255];
+        AVFilterContext *filt_crop;
+        snprintf(crop_args, 255, "%d:%d:%d:%d", ost->leftBand, ost->topBand,
+                 codec->width -  (frame_padleft + frame_padright),
+                 codec->height - (frame_padtop + frame_padbottom));
+        filt_crop = avfilter_open(avfilter_get_by_name("crop"), NULL);
+        if (!filt_crop)
+            return -1;
+        if (avfilter_init_filter(filt_crop, crop_args, NULL))
+            return -1;
+        if (avfilter_link(curr_filter, 0, filt_crop, 0))
+            return -1;
+        curr_filter = filt_crop;
+        avfilter_graph_add_filter(filt_graph_all, curr_filter);
+    }
+
+    if((codec->width !=
+        icodec->width - (frame_leftBand + frame_rightBand) +
+        (frame_padleft + frame_padright)) ||
+       (codec->height != icodec->height - (frame_topBand  + frame_bottomBand) +
+        (frame_padtop + frame_padbottom))) {
+        char crop_args[255];
+        AVFilterContext *filt_scale;
+        snprintf(crop_args, 255, "%d:%d", codec->width -
+                                             (frame_padleft + frame_padright),
+                 codec->height - (frame_padtop + frame_padbottom));
+        filt_scale = avfilter_open(avfilter_get_by_name("scale"), NULL);
+        if (!filt_scale)
+            return -1;
+        if (avfilter_init_filter(filt_scale, crop_args, NULL))
+            return -1;
+        if (avfilter_link(curr_filter, 0, filt_scale, 0))
+            return -1;
+        curr_filter = filt_scale;
+        avfilter_graph_add_filter(filt_graph_all, curr_filter);
+    }
+
+    if(vfilters) {
+        AVFilterInOut *outputs = av_malloc(sizeof(AVFilterInOut));
+        AVFilterInOut *inputs  = av_malloc(sizeof(AVFilterInOut));
+
+        outputs->name    = av_strdup("in");
+        outputs->filter  = curr_filter;
+        outputs->pad_idx = 0;
+        outputs->next    = NULL;
+
+        inputs->name    = av_strdup("out");
+        inputs->filter  = ist->out_video_filter;
+        inputs->pad_idx = 0;
+        inputs->next    = NULL;
+
+        if (avfilter_parse_graph(filt_graph_all, vfilters, inputs, outputs, NULL) < 0)
+            return -1;
+    } else {
+        if(avfilter_link(curr_filter, 0, ist->out_video_filter, 0) < 0)
+            return -1;
+    }
+
+    /* configure all the filter links */
+    if(avfilter_graph_config_formats(filt_graph_all))
+        return -1;
+    if(avfilter_config_links(ist->out_video_filter))
+        return -1;
+
+    codec->width = ist->out_video_filter->inputs[0]->w;
+    codec->height = ist->out_video_filter->inputs[0]->h;
+
+    return 0;
+}
+#endif /* ENABLE_AVFILTER */
+
 static void term_exit(void)
 {
 #ifdef HAVE_TERMIOS_H
@@ -808,6 +1084,9 @@
     if (nb_frames <= 0)
         return;
 
+#if ENABLE_AVFILTER
+    formatted_picture = in_picture;
+#else
     if (ost->video_crop) {
         if (av_picture_crop((AVPicture *)&picture_crop_temp, (AVPicture *)in_picture, dec->pix_fmt, ost->topBand, ost->leftBand) < 0) {
             av_log(NULL, AV_LOG_ERROR, "error cropping picture\n");
@@ -817,6 +1096,7 @@
     } else {
         formatted_picture = in_picture;
     }
+#endif
 
     final_picture = formatted_picture;
     padding_src = formatted_picture;
@@ -832,12 +1112,14 @@
         }
     }
 
+#if !ENABLE_AVFILTER
     if (ost->video_resample) {
         padding_src = NULL;
         final_picture = &ost->pict_tmp;
         sws_scale(ost->img_resample_ctx, formatted_picture->data, formatted_picture->linesize,
               0, ost->resample_height, resampling_dst->data, resampling_dst->linesize);
     }
+#endif
 
     if (ost->video_pad) {
         av_picture_pad((AVPicture*)final_picture, (AVPicture *)padding_src,
@@ -1107,6 +1389,7 @@
     static short *samples= NULL;
     AVSubtitle subtitle, *subtitle_to_free;
     int got_subtitle;
+    int loop;
 
     if(ist->next_pts == AV_NOPTS_VALUE)
         ist->next_pts= ist->pts;
@@ -1219,6 +1502,17 @@
                                     &buffer_to_free);
         }
 
+#if ENABLE_AVFILTER
+        if (ist->st->codec->codec_type == CODEC_TYPE_VIDEO) {
+            // add it to be filtered
+            memcpy(ist->filter_frame->data,  picture.data,
+                   sizeof(picture.data));
+            memcpy(ist->filter_frame->linesize, picture.linesize,
+                   sizeof(picture.linesize));
+            ist->has_filter_frame = 1;
+        }
+#endif
+
         // preprocess audio (volume)
         if (ist->st->codec->codec_type == CODEC_TYPE_AUDIO) {
             if (audio_volume != 256) {
@@ -1256,9 +1550,16 @@
             }
         }
 #endif
+        loop = ist->st->codec->codec_type != CODEC_TYPE_VIDEO ||
+            avfilter_poll_frame(ist->out_video_filter->inputs[0]);
         /* if output time reached then transcode raw format,
            encode packets and output them */
         if (start_time == 0 || ist->pts >= start_time)
+#if ENABLE_AVFILTER
+        while(loop) {
+            if (ist->st->codec->codec_type == CODEC_TYPE_VIDEO)
+                get_filtered_video_pic(ist->out_video_filter, &ist->picref, &picture, &ist->pts);
+#endif
             for(i=0;i<nb_ostreams;i++) {
                 int frame_size;
 
@@ -1281,6 +1582,9 @@
                             do_audio_out(os, ost, ist, data_buf, data_size);
                             break;
                         case CODEC_TYPE_VIDEO:
+#if ENABLE_AVFILTER
+                            ost->st->codec->sample_aspect_ratio = ist->picref->pixel_aspect;
+#endif
                             do_video_out(os, ost, ist, &picture, &frame_size);
                             video_size += frame_size;
                             if (vstats_filename && frame_size)
@@ -1339,7 +1643,15 @@
                         av_free_packet(&opkt);
                     }
                 }
+                loop =  (ist->st->codec->codec_type == CODEC_TYPE_VIDEO) &&
+                        avfilter_poll_frame(ist->out_video_filter->inputs[0]);
             }
+
+#if ENABLE_AVFILTER
+            if(ist->picref)
+                avfilter_unref_pic(ist->picref);
+        }
+#endif
         av_free(buffer_to_free);
         /* XXX: allocate the subtitles in the codec ? */
         if (subtitle_to_free) {
@@ -1748,10 +2060,21 @@
                         fprintf(stderr, "Cannot get resampling context\n");
                         av_exit(1);
                     }
+#if ENABLE_AVFILTER
+                    ost->resample_height = icodec->height;
+#else
                     ost->resample_height = icodec->height - (frame_topBand + frame_bottomBand);
+#endif
                 }
                 ost->encoding_needed = 1;
                 ist->decoding_needed = 1;
+
+#if ENABLE_AVFILTER
+                if (configure_filters(ist, ost)) {
+                    fprintf(stderr, "Error opening filters!\n");
+                    exit(1);
+                }
+#endif
                 break;
             case CODEC_TYPE_SUBTITLE:
                 ost->encoding_needed = 1;
@@ -3718,6 +4041,9 @@
 #ifdef CONFIG_VHOOK
     { "vhook", HAS_ARG | OPT_EXPERT | OPT_VIDEO, {(void*)add_frame_hooker}, "insert video processing module", "module" },
 #endif
+#if ENABLE_AVFILTER
+    { "vfilters", OPT_STRING | HAS_ARG, {(void*)&vfilters}, "video filters", "filter list" },
+#endif
     { "intra_matrix", HAS_ARG | OPT_EXPERT | OPT_VIDEO, {(void*)opt_intra_matrix}, "specify intra matrix coeffs", "matrix" },
     { "inter_matrix", HAS_ARG | OPT_EXPERT | OPT_VIDEO, {(void*)opt_inter_matrix}, "specify inter matrix coeffs", "matrix" },
     { "top", HAS_ARG | OPT_EXPERT | OPT_VIDEO, {(void*)opt_top_field_first}, "top=1/bottom=0/auto=-1 field first", "" },
