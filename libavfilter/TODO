FRAMEWORK:
- auto-inserting needed filters (colorspace conversion, buffer, etc)
- pass info needed to reorder decode ordered frames
- other useful image flags? interlace? top/bottom field first? aspect ratio?

POSSIBLE FRAMEWORK IDEAS:
- can colorspace negotiation be improved?
- can parameter passing be done better with AVOption?
- support for running different filters in different threads?
- ability to reuse same memory for multiple slices?

FILTERS:
- padding
- colorspace conversion
- scaling (combine with conversion like mplayer?)
- deslicify
- decode order -> display order
- fifo buffer to buffer previous frames needed for next filter context
- spatial context providing filter
- splitter, feeding a single input to multiple filters to test multiple outputs
- decimate to test non 1:1 input:output ratios
- naive temporal blur to test buffering of previous frames
- naive spatial blur to test spatial context

FILTER IDEAS:
- port vhook filters

PROGRAMS:
- make ffmpeg support filters - use filter graphs. allow simple chains
  specified on the command line.  complex graphs may need a graph description
  from a file.

DOCUMENTATION:
- more & better doxy comments
- filter writing tutorial
- filter using tutorial

